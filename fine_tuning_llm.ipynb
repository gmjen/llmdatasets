{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2991c3-ea29-43e3-8b98-e2f30f340306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "# accuracy - does it match or not?\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e9ce9-df6d-4642-b949-2a674c9f15e9",
   "metadata": {},
   "source": [
    "using dataset from: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0047349a-91fd-4c97-985b-dcaaf6239a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('https://raw.githubusercontent.com/gmjen/llmdatasets/main/amazon_cells_labelled.txt', sep='\\t',\n",
    "                           names=[\"review\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca21e6ce-3bad-415f-81cb-c48b1f8e23a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_df['review'] = reviews_df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d60d5d0-9ba6-4bf3-8d80-d6d21c968c48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case, excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>if you are razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and the sound quality is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>excellent product.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>it is the best charger i have seen on the mark...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>sweetest phone!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>:-)oh, the charger seems to work fine.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>it fits so securely that the ear hook does not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  label\n",
       "1                          good case, excellent value.      1\n",
       "2                               great for the jawbone.      1\n",
       "4                                    the mic is great.      1\n",
       "7          if you are razr owner...you must have this!      1\n",
       "10                     and the sound quality is great.      1\n",
       "..                                                 ...    ...\n",
       "971                                 excellent product.      1\n",
       "975  it is the best charger i have seen on the mark...      1\n",
       "976                                  sweetest phone!!!      1\n",
       "977             :-)oh, the charger seems to work fine.      1\n",
       "978  it fits so securely that the ear hook does not...      1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[reviews_df['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9557904-312a-4e95-bea1-d753e5b6b5a5",
   "metadata": {},
   "source": [
    "create a Dataset object to for the Transformers library to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde58bb5-2adb-440d-a067-56a7b8b188a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_reviews = Dataset.from_pandas(reviews_df)\n",
    "\n",
    "# already has convenient train_test_split method\n",
    "dataset = dataset_reviews.train_test_split(test_size=0.2, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f7f976-80ce-46e7-a79f-40b6549abdcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e602c8f7-c15a-4098-947d-6fd03944964d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42)\n",
    "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883b7e3f-8ebf-42e0-87c4-d9b48d6fb6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'the biggest complaint i have is, the battery drains superfast.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56893b4a-54c1-428e-a098-d17f79e7feff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'it fits my ear well and is comfortable on.', 'label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e36562c-e7dc-48f0-9edd-a863a3464555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0065500736236572266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 800,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0061838626861572266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 200,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True, max_length = 128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd70c78-4847-4bc7-bf28-4bfcf33dec0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ec4173-c843-44bd-a338-09aa439441f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it worked very well.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0857c3-02e3-4789-a7bd-2cb445fcae6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bd3897-e31b-48d6-bf9b-3057448b057f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 2009, 2499, 2200, 2092, 1012,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49e3b3-2be1-4ce1-8df6-ac9e5c5c6f4c",
   "metadata": {},
   "source": [
    "[CLS] is a special token used in the BERT (Bidirectional Encoder Representations from Transformers) architecture. It stands for \"classification\" and is used as the first token in the input sequence. The [CLS] token is followed by the input text, and the output of the final hidden layer corresponding to the [CLS] token is used as the input to the classifier for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee16c8b-c63d-4b2c-bf82-2340d1207d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[CLS]', 'it', 'worked', 'very', 'well', '.', '[SEP]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',\n",
       "       '[PAD]'], dtype='<U6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tokenizer.convert_ids_to_tokens(train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f45ac-9b90-4f15-90f7-024469b80c66",
   "metadata": {},
   "source": [
    "Transformers has a Trainer class optimized to train Transformers models which we'll use here.\n",
    "\n",
    "num_labels specifies the number of labels in your classification task.\n",
    "\n",
    "In the case of the BERT model with AutoModelForSequenceClassification, the last layer of the model is a linear layer that maps the hidden representation of the input sequence to a vector of size num_labels. This final layer is then passed through a softmax function to convert the output to a probability distribution over the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d2a700-9cf1-4dbc-91a4-efa23b079600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6409b78-450d-4bd0-b436-099072d2e5e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "You will see a warning about some of the pretrained weights not being used and some weights being randomly initialized. Don't worry, this is completely normal! The pretrained head of the BERT model is discarded, and replaced with a randomly initialized classification head. You will fine-tune this new model head on your sequence classification task, transferring the knowledge of the pretrained model to it.\n",
    "\n",
    "Training hyperparameters\n",
    "\n",
    "Next, create a TrainingArguments class which contains all the hyperparameters you can tune as well as flags for activating different training options. For this tutorial you can start with the default training hyperparameters, but feel free to experiment with these to find your optimal settings.\n",
    "\n",
    "Specify where to save the checkpoints from your training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "756a3774-7cf9-495a-ab04-74f06ba8db05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b8efb-bbb2-4cf4-adeb-3885b5282401",
   "metadata": {},
   "source": [
    "The accuracy metric is a common evaluation metric used to measure the performance of a classification model. It measures the proportion of correctly classified samples out of the total number of samples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "910ea9ce-2c05-46f0-8269-1532ca055b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2603f55-e71c-4483-a731-e00dab4b9ae0",
   "metadata": {},
   "source": [
    "eval_pred argument is a tuple containing the predicted logits and the true labels. Predicted logits are the output of the classifier, which represents the model's confidence for each class for each example. The true labels are the actual labels of the examples.\n",
    "\n",
    "The np.argmax function is used to obtain the predicted class for each example. It takes the logits as input and gives us the index of the class with the highest confidence score.\n",
    "\n",
    "Finally, the metric.compute function is used to compute the evaluation metric based on the predicted class and the true label for each example. The metric here refers to a specific evaluation metric object that was defined earlier in the code. The compute function takes two arguments - the predicted classes and the true labels - and returns the computed metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b07467-7b8c-4e00-8128-86ca9a6dae06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e72d4c4-2e4b-4b50-ad6b-d43b40d47cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0ffad-3076-4e8a-94d8-7cbfd1f8d31b",
   "metadata": {},
   "source": [
    "Create a Trainer object with your model, training arguments, training and test datasets, and evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e46bcf9e-ae6c-4644-a9d6-5ff0449a5d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4b3e4-27de-4c30-8fe4-2a9560b389c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c6c2112-ff58-41d4-95a2-937535b677d2",
   "metadata": {},
   "source": [
    "Now call `.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b557c0d-c1e7-4a80-ac4e-46542f51ac39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review. If review are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 800\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "  Number of trainable parameters = 109483778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 01:19, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164417</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284929</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279440</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285909</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review. If review are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review. If review are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review. If review are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review. If review are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.1590566062927246, metrics={'train_runtime': 80.4307, 'train_samples_per_second': 39.786, 'train_steps_per_second': 4.973, 'total_flos': 210488844288000.0, 'train_loss': 0.1590566062927246, 'epoch': 4.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42efac88-ec4d-42be-a7dc-a77b187a60f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee585eb-151d-4c96-a149-ae619e11a7ab",
   "metadata": {},
   "source": [
    "In PyTorch, the model.eval() method sets the model to evaluation mode. This is important because the behavior of certain layers, such as dropout and batch normalization, can differ between training and inference.\n",
    "\n",
    "During training, dropout is used to randomly drop out units from the network to prevent overfitting. Batch normalization is used to normalize the activations of each layer to speed up training and improve performance.\n",
    "\n",
    "During inference, we don't want to use dropout because we want to use the entire network for predictions. We also don't want to normalize the activations of each layer based on the statistics of the current mini-batch, because we are making predictions on individual samples. Therefore, we need to set the model to evaluation mode to ensure that these layers are applied correctly during inference.\n",
    "\n",
    "When you call model.eval(), it sets the training attribute of the model to False, which disables dropout and batch normalization. It also freezes the parameters of the model, so that they are not updated during inference. This ensures that the model behaves consistently during inference and improves the accuracy of the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b911dd5b-e0cb-4c4c-9e67-18cf0168ae59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def eval_review(rev):\n",
    "    # set the model to evaluation mode\n",
    "\n",
    "    inputs = tokenizer(rev, return_tensors=\"pt\")\n",
    "\n",
    "    # move the input tensor to the same device as the model\n",
    "    inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "\n",
    "    # pass the input through the model to get the output logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # convert the logits to probabilities using a softmax function\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # get the predicted label by selecting the index with the highest probability\n",
    "    predicted_label = torch.argmax(probs, dim=-1)\n",
    "\n",
    "    # return the predicted label\n",
    "    return(predicted_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a8ce3d5-295d-44d5-be64-38cab2f77b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_review(\"I really don't like this thing at all.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57de9286-24dc-4898-9afc-4133738ea824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_review(\"It's amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "873a93b7-27cc-4397-b2f1-802a9b2c67aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_review(\"I didn't know what to think but it turned out to be good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6768e7-fb78-43bd-a31f-82cd19ae8f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
